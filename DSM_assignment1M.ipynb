{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "**Deadline**:  09/09/2019, 9.59am\n",
    "\n",
    "**Names and student numbers:**\n",
    "1. Philip Lankhorst (student number)\n",
    "2. Carmella Bierma\n",
    "3. Milena van der Velde (11016647)\n",
    "\n",
    "**Declaration of Originality**\n",
    "\n",
    "We whose names are given under 1., 2. and 3. above declare that:\n",
    "1. These solutions are solely our own work.\n",
    "2. We have not made (part of) these solutions available to any other student.\n",
    "\n",
    "## Instructions for completing and submitting the assignment\n",
    "Please pay attention to the following instructions:\n",
    "1. Please follow carefully the steps outlined in the assignment. If you cannot solve an exercise and this hinders continuing with subsequent exercises, try to find a way to work around it and give a clear explanation for the solution you have chosen.\n",
    "2. Submit your work in the form of a Jupyter notebook via Canvas, before the deadline. Your notebook should not give errors when executed with `Run All`.\n",
    "4. You are allowed to work on the assignment in groups of 2 or 3 students and to submit together. Before you submit, you and your team members have to register as an **Assignment group** on Canvas. Only a single member of each group has to submit the notebook. Please do **NOT** submit the same notebook multiple times!\n",
    "5. Please write your names also inside this markdown cell, under **Names and student numbers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: importing the relevant libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** import all the libraries you are using in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: using the Python Standard Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** write a function called `sort_words`. The function should have a single argument, which is always a string of words separated by spaces. For example, `sample` in the cell below is such a string. The function should return another string containing the same words separated by spaces, but now the words must be ordered alphabetically by their first letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are', 'coding', 'exercises', 'fun', 'or', 'what?']\n"
     ]
    }
   ],
   "source": [
    "sample = \"coding what? fun are exercises or\"\n",
    "def sort_words(words):\n",
    "    \"\"\"Sort words in alphabetic order for a given string\"\"\"\n",
    "    \n",
    "    sortedwords = words.split()\n",
    "    sortedwords.sort()\n",
    "    return sortedwords\n",
    "\n",
    "print(sort_words(sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** below you find three cells. In the first cell three NumPy objects (`v`, `u` and `A`) are defined, depending on an integer parameter `n`. In the second cell, these objects are used to compute a quantity that you might know from your linear algebra course. In this exercise, you have to perform two tasks:\n",
    "* in the third cell, compute the quantity of the second cell again, but now without the use of any (for) loops. Print the result to verify that your code indeed computes the same quantity.\n",
    "* use Python's `time` module to measure the time the computations in the second and third cell take, separately. Notice that if you increase `n` (to for example 2000), the relative difference in computational efficiency grows rapidly.\n",
    "\n",
    "[NB: When your run a vectorized computation for the first time, Python loads some additional libraries in the background. This takes additional time. Therefore, you have to run the vectorized computation (at least) twice to get a good estimate of the computational time.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "v = np.random.normal(size=n)\n",
    "u = np.random.normal(size=n)\n",
    "A = np.random.normal(size=(n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195.260283726801\n"
     ]
    }
   ],
   "source": [
    "result = 0\n",
    "for i in range(len(v)):\n",
    "    for j in range(len(u)):\n",
    "        result += v[i]*A[i,j]*u[j]\n",
    "        \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195.2602837267999\n"
     ]
    }
   ],
   "source": [
    "print(sum(v.dot(A)*u))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: wrangling and analyzing Twitter sentiment data\n",
    "This part of the assignment is about wrangling and analyzing Twitter sentiment data for six airline companies:\n",
    "\n",
    "|**Name Airline**|**@username**|\n",
    "|:-------|:-------------|\n",
    "|American Airlines       |@AmericanAir           |\n",
    "|JetBlue Airways        |@JetBlue              |\n",
    "|Southwest Airlines       |@SouthwestAir           |\n",
    "|United Airlines        |@united              |\n",
    "|US Airways        |@USAirways              |\n",
    "|Virgin America       |@VirginAmerica             |\n",
    "\n",
    "The dataset `airline_twitter_sentiment.csv` consists of more than 14.000 tweets sent on 9 consecutive days in February 2015, all addressing one (or more) of the aforementioned airlines via the @username syntax. The text of the tweets can be found in the `text` column of the dataset. Furthermore, a machine learning algorithm has analyzed the content of the tweets and categorized the sentiment as positive, neutral or negative. This can be found in the `airline_sentiment` column. The machine learning algorithm also estimates the probability that it identified the correct sentiment, which is given in the `airline_sentiment:confidence` column. Another relevant column is called `tweet_created`, giving the time and day at which the tweet was sent.\n",
    "\n",
    "(Note: US Airways was integrated into American Airlines in October 2015. Since our dataset is from February 2015, we will consider them as separate airlines.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** import the dataset `airline_twitter_sentiment.csv` and turn it into a DataFrame called `df`. Print the total number of tweets in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14694\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('airline_twitter_sentiment.csv')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** print the first 10 rows of the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448223</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:57</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cuschoolie1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica help, left expensive headphones...</td>\n",
       "      <td>[33.94209449, -118.40410103]</td>\n",
       "      <td>2/23/15 21:10</td>\n",
       "      <td>5.700880e+17</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681452067</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 0:41</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flight Booking Problems</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERBARAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united very exasperating I'm having a difficu...</td>\n",
       "      <td>[41.86591215, -87.6231126]</td>\n",
       "      <td>2/20/15 21:36</td>\n",
       "      <td>5.690080e+17</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681451479</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 4:43</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CoachMcRoberts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Can you help me get a flight out tonig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/21/15 16:58</td>\n",
       "      <td>5.693000e+17</td>\n",
       "      <td>Oxford, MS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681456798</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:27</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flight Booking Problems</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4starcashier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir 4/9/14, I need to fly from GSP t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/17/15 12:37</td>\n",
       "      <td>5.677850e+17</td>\n",
       "      <td>Des Moines, Iowa</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681461929</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Damaged Luggage</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WTFloris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways Oh yes, because I had loads of time...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/21/15 1:54</td>\n",
       "      <td>5.690730e+17</td>\n",
       "      <td>Raxacoricofallapatorius</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  681448223    False   finalized                   3      2/25/15 1:57   \n",
       "1  681452067    False   finalized                   3      2/25/15 0:41   \n",
       "2  681451479    False   finalized                   3      2/25/15 4:43   \n",
       "3  681456798    False   finalized                   3      2/25/15 3:27   \n",
       "4  681461929    False   finalized                   3      2/25/15 3:50   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence           negativereason  \\\n",
       "0          negative                           1.0   Customer Service Issue   \n",
       "1          negative                           1.0  Flight Booking Problems   \n",
       "2           neutral                           1.0                      NaN   \n",
       "3          negative                           1.0  Flight Booking Problems   \n",
       "4          negative                           1.0          Damaged Luggage   \n",
       "\n",
       "   negativereason:confidence airline_sentiment_gold            name  \\\n",
       "0                     1.0000                    NaN     Cuschoolie1   \n",
       "1                     0.6939                    NaN        MERBARAT   \n",
       "2                        NaN                    NaN  CoachMcRoberts   \n",
       "3                     1.0000                    NaN    4starcashier   \n",
       "4                     0.6663                    NaN        WTFloris   \n",
       "\n",
       "  negativereason_gold  retweet_count  \\\n",
       "0                 NaN              0   \n",
       "1                 NaN              0   \n",
       "2                 NaN              0   \n",
       "3                 NaN              0   \n",
       "4                 NaN              0   \n",
       "\n",
       "                                                text  \\\n",
       "0  @VirginAmerica help, left expensive headphones...   \n",
       "1  @united very exasperating I'm having a difficu...   \n",
       "2  @united Can you help me get a flight out tonig...   \n",
       "3  @SouthwestAir 4/9/14, I need to fly from GSP t...   \n",
       "4  @USAirways Oh yes, because I had loads of time...   \n",
       "\n",
       "                    tweet_coord  tweet_created      tweet_id  \\\n",
       "0  [33.94209449, -118.40410103]  2/23/15 21:10  5.700880e+17   \n",
       "1    [41.86591215, -87.6231126]  2/20/15 21:36  5.690080e+17   \n",
       "2                           NaN  2/21/15 16:58  5.693000e+17   \n",
       "3                           NaN  2/17/15 12:37  5.677850e+17   \n",
       "4                           NaN   2/21/15 1:54  5.690730e+17   \n",
       "\n",
       "            tweet_location               user_timezone  \n",
       "0            Washington DC                       Quito  \n",
       "1              Chicago, IL  Central Time (US & Canada)  \n",
       "2               Oxford, MS                         NaN  \n",
       "3         Des Moines, Iowa  Central Time (US & Canada)  \n",
       "4  Raxacoricofallapatorius                   Amsterdam  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** create a list of the names of the columns of the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [column for column in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** during the creation of the dataset some lines/rows were duplicated. Remove them from `df`, such that the DataFrame `df` does not contain any duplicates anymore. Count the total number of duplicates and print this number in a nice sentence that explains the meaning of the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of dupiclates in the data are 54\n"
     ]
    }
   ],
   "source": [
    "print('The amount of dupiclates in the data are',len(df) - len(df.drop_duplicates()))\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:** the machine learning algorithm is not always able to extract a sentiment from the tweet. This is reflected in a missing `airline_sentiment` value. Remove the lines with a missing airline sentiment from the `df`. As in the previous exercise, report the number of discarded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14640\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:** the column `airline_sentiment:confidence` represents the probability that the machine learning algorithm predicted the correct sentiment. Remove the lines from `df` with an airline-sentiment confidence below 0.50. Report the number of discarded tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10:** the columns `text` contains the text of the tweets. Remove the lines from `df` with tweets containing less than 50 characters. Report the number of discarded tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11:** print a frequency table for the total number of positive, neutral and negative tweets in the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12:** show that the elements of the column `tweet_created` are of string (`str`) type. [Hint: it is enough if you show this for only one element of the column, for example by using `.at[...]` to access the values of a DataFrame.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 13:** using strings to specify a day and time is often inconvenient. One way of resolving this issue is by using a Timestamp object, which is part of the pandas library. Turn the elements of the column `tweet_created` into Timestamp objects. This means that the column `tweet_created` of the resulting DataFrame `df` has to contain these Timestamp objects, instead of strings. [Hint: see section 11.1 of the McKinney book.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 14:** turn the column `tweet_created` into the index of the DataFrame `df`. Finally, print the first 5 rows of the resulting DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 15:** sort the rows in the DataFrame by the time the tweet was created. The tweet that was created first, should be on top of the DataFrame. Print the first 5 rows of the resulting DataFrame `df` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 16:** check explicitly whether all tweets have a unique index. [Hint: see section 11.2 of the McKinney book.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 17:** all tweets in our dataset were sent on 9 consecutive days in February 2015. Add a new column called `day` to the DataFrame `df`. The elements of this column should represent the day of the month on which the tweet was created (e.g. `19` for a tweet created on 19 February 2015). For this exercise, use that the index of `df` that you created is not of a standard Index type, by of DatetimeIndex type, which has a `day` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 18:** print a frequency table for the total number of tweets per day. Sort the table by day, starting with the earliest day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
